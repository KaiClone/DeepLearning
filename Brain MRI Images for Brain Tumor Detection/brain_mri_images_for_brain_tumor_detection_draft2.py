# -*- coding: utf-8 -*-
"""brain-mri-images-for-brain-tumor-detection-draft2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YgkcHoaZdtsaZVeaNWMjz8hu8WKY9eUo
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
'''for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))
'''
# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

"""# Libraries"""

# Core libraries
import numpy as np
import pandas as pd
import math
import os, shutil
# Dataset download
import kagglehub
# Visualization
import matplotlib.pyplot as plt
import seaborn as sns

import random
from PIL import Image
from tqdm import tqdm  # for checking currupt images
import cv2 # for image quality
import random

from sklearn.feature_selection import mutual_info_classif, RFE, SelectKBest, f_classif
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, precision_score, recall_score, precision_score, confusion_matrix, roc_curve, auc

import torch
import torch.nn as nn
from torchvision import transforms, models  #PyTorch
from torch.utils.data import Dataset, DataLoader,WeightedRandomSampler
import torch.optim as optim
from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR, CosineAnnealingLR
import torch.nn.functional as F
import optuna

from torchvision.models import efficientnet_b0
from torchvision.models import densenet121

#documentation
!pip install python-docx
from docx import Document
from docx.shared import Inches, Pt
from docx.enum.text import WD_ALIGN_PARAGRAPH

"""# Load Dataset"""

# Download the dataset
path = kagglehub.dataset_download("navoneel/brain-mri-images-for-brain-tumor-detection")

print("Path to dataset files:", path)

os.makedirs("results/tables", exist_ok=True)
os.makedirs("results/plots", exist_ok=True)

print(os.listdir(path))

# Define your dataset path
dataset_path = os.path.join(path, 'brain_tumor_dataset')

# Initialize list to hold image info
image_data = []


valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff')
# Loop through both folders
for label in ['yes', 'no']:
    folder_path = os.path.join(dataset_path, label)
    for filename in os.listdir(folder_path):
        if filename.lower().endswith(valid_extensions):
            image_data.append({
                'filename': filename.strip(),  # removes leading/trailing spaces
                'label': label,
                'path': os.path.join(folder_path, filename.strip())  # Add full path here
            })

# Convert to DataFrame
df = pd.DataFrame(image_data)

# Preview the first few rows
print(df.head())

# Save to CSV for reporting
head_table_path = "results/tables/image_data_head.csv"
df.head().to_csv(head_table_path, index=False)

print(f"✅ Image data head saved: {head_table_path}")

df.shape

# Shuffle the dataframe
df = df.sample(frac=1, random_state=42).reset_index(drop=True)
# Preview the first few rows
print(df.head())

# Encode diagnosis: B=0 (benign), M=1 (malignant)
#df_encoded = df.copy()
df["label"] = df["label"].map({"no":0, "yes":1})
# Preview the first few rows
print(df.head())

"""# EDA (Exploratory Data Analysis)

**Class Distribution**
"""

df['label'].value_counts()
# Save class distribution (diagnosis counts)
class_dist_path = "results/tables/class_distribution.csv"
df["label"].value_counts().to_csv(class_dist_path)

print(f"✅ Class distribution saved: {class_dist_path}")
print(df["label"].value_counts())

# Create the plots directory if it doesn't exist
os.makedirs("results/plots", exist_ok=True)

# Plot
sns.countplot(data=df, x="label", palette="Set2")
plt.title("Class Distribution (yes vs no)")
# Remove legend if you don't want it
plt.legend().remove()
# Save plot as PNG to 'plots' folder
plt.savefig("results/plots/class_distribution.png", dpi=300, bbox_inches="tight")

# Show plot
plt.show()

"""**Visualizing Random Samples**"""

fig, axes = plt.subplots(2, 5, figsize=(12, 6))
labels = df['label'].unique()

for i, label in enumerate(labels):
    sample_df = df[df['label'] == label].sample(5, random_state=42)
    for j, file in enumerate(sample_df['path'].values):
        img = Image.open(file)
        axes[i, j].imshow(img, cmap='gray')
        axes[i, j].set_title(label)
        axes[i, j].axis('off')

plt.suptitle("Random Samples from Each Class")
plt.show()

"""**Analyzing different resolutions**"""

df['size'] = df['path'].apply(lambda x: Image.open(x).size)
df['width'], df['height'] = zip(*df['size'])
# Calculate aspect ratio
df['aspect_ratio'] = df['width'] / df['height']

plt.figure(figsize=(10, 5))

# Plot width distribution
plt.hist(df['width'], bins=30, alpha=0.6, color='blue', label='Width')

# Plot height distribution
plt.hist(df['height'], bins=30, alpha=0.6, color='orange', label='Height')

plt.title("Image Dimensions Distribution")
plt.xlabel("Pixels")
plt.ylabel("Frequency")
plt.legend()
plt.tight_layout()
plt.savefig("results/plots/image_dimensions_distribution.png", dpi=300, bbox_inches="tight")
plt.show()

# Plot aspect ratio distribution
plt.figure(figsize=(8, 4))
plt.hist(df['aspect_ratio'], bins=30, color='green', alpha=0.7)
plt.title("Aspect Ratio Distribution (Width / Height)")
plt.xlabel("Aspect Ratio")
plt.ylabel("Frequency")
plt.tight_layout()
plt.savefig("results/plots/aspect_ratio_distribution.png", dpi=300, bbox_inches="tight")
plt.show()

# Define color map based on label
colors = df['label'].map({0: 'blue', 1: 'red'})  # Non-tumor: blue, Tumor: red

# Scatter plot of width vs. height with color-coded labels
plt.figure(figsize=(8, 6))
scatter = plt.scatter(df['width'], df['height'], c=colors, alpha=0.6, edgecolors='w', linewidths=0.5)

# Create custom legend
from matplotlib.patches import Patch
legend_elements = [Patch(facecolor='blue', edgecolor='w', label='Non-Tumor'),
                   Patch(facecolor='red', edgecolor='w', label='Tumor')]
plt.legend(handles=legend_elements, title="Image Class")

plt.title("Scatter Plot of Image Dimensions by Class")
plt.xlabel("Width (pixels)")
plt.ylabel("Height (pixels)")
plt.grid(True)
plt.tight_layout()
plt.savefig("results/plots/image_dimensions_scatter_by_class.png", dpi=300, bbox_inches="tight")
plt.show()

df.shape

"""**Analyzing brightness/contrast**

"""

# Compute average intensity and contrast (standard deviation) for each image
df['avg_intensity'] = df['path'].apply(lambda x: np.array(Image.open(x).convert("L")).mean())
df['contrast'] = df['path'].apply(lambda x: np.array(Image.open(x).convert("L")).std())

# Plot average intensity distribution
plt.figure(figsize=(10, 5))
plt.hist(df['avg_intensity'], bins=50, color='gray', edgecolor='black')
plt.title("Average Pixel Intensity Distribution")
plt.xlabel("Intensity")
plt.ylabel("Frequency")
plt.tight_layout()
plt.savefig("results/plots/average_intensity_distribution.png", dpi=300, bbox_inches="tight")
plt.show()

# Plot contrast distribution
plt.figure(figsize=(10, 5))
plt.hist(df['contrast'], bins=50, color='darkred', edgecolor='black')
plt.title("Image Contrast Distribution (Standard Deviation of Intensity)")
plt.xlabel("Contrast")
plt.ylabel("Frequency")
plt.tight_layout()
plt.savefig("results/plots/image_contrast_distribution.png", dpi=300, bbox_inches="tight")
plt.show()

"""Removing low contrast (intensity) samples"""

intensity_threshold = 10
df = df[df['avg_intensity'] > intensity_threshold].reset_index(drop=True)

df.shape

# Split data by class
tumor_df = df[df['label'] == 1]
non_tumor_df = df[df['label'] == 0]

# Plot contrast distribution per class
plt.figure(figsize=(10, 5))
plt.hist(non_tumor_df['contrast'], bins=50, alpha=0.6, color='blue', label='Non-Tumor')
plt.hist(tumor_df['contrast'], bins=50, alpha=0.6, color='red', label='Tumor')
plt.title("Image Contrast Distribution by Class")
plt.xlabel("Contrast (Standard Deviation of Intensity)")
plt.ylabel("Frequency")
plt.legend()
plt.tight_layout()
plt.savefig("results/plots/contrast_distribution_by_class.png", dpi=300, bbox_inches="tight")
plt.show()

# Plot intensity distribution per class
plt.figure(figsize=(10, 5))
plt.hist(non_tumor_df['avg_intensity'], bins=50, alpha=0.6, color='blue', label='Non-Tumor')
plt.hist(tumor_df['avg_intensity'], bins=50, alpha=0.6, color='red', label='Tumor')
plt.title("Average Pixel Intensity Distribution by Class")
plt.xlabel("Intensity")
plt.ylabel("Frequency")
plt.legend()
plt.tight_layout()
plt.savefig("results/plots/intensity_distribution_by_class.png", dpi=300, bbox_inches="tight")
plt.show()

"""**Removing currupt or dublicate samples**"""

bad_files = []
for path in tqdm(df['path']):
    try:
        img = Image.open(path)
        img.verify()  # verify is lightweight check
    except:
        bad_files.append(path)

print("Corrupted Images:", bad_files)

"""**Analyzing Sharpness and noise**"""

# Compute Laplacian variance for sharpness
def compute_sharpness(path):
    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
    return cv2.Laplacian(img, cv2.CV_64F).var()

df['sharpness'] = df['path'].apply(compute_sharpness)

# Plot sharpness distribution
plt.figure(figsize=(10, 5))
plt.hist(df['sharpness'], bins=50, color='teal', edgecolor='black')
plt.title("Image Sharpness Distribution (Laplacian Variance)")
plt.xlabel("Sharpness")
plt.ylabel("Frequency")
plt.tight_layout()
plt.savefig("results/plots/image_sharpness_distribution.png", dpi=300, bbox_inches="tight")
plt.show()

# Estimate noise level
def compute_noise(path):
    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
    blurred = cv2.GaussianBlur(img, (3, 3), 0)
    noise = img.astype(np.float32) - blurred.astype(np.float32)
    return noise.std()

df['noise'] = df['path'].apply(compute_noise)

# Plot noise distribution
plt.figure(figsize=(10, 5))
plt.hist(df['noise'], bins=50, color='darkorange', edgecolor='black')
plt.title("Estimated Image Noise Distribution")
plt.xlabel("Noise Level")
plt.ylabel("Frequency")
plt.tight_layout()
plt.savefig("results/plots/image_noise_distribution.png", dpi=300, bbox_inches="tight")
plt.show()

"""**Removing blurry samples**"""

# Flag blurry images
blur_threshold = 100
df['is_blurry'] = df['sharpness'] < blur_threshold

# Count blurry images
num_blurry = df['is_blurry'].sum()
print(f"Blurry images detected: {num_blurry} out of {len(df)}")

df = df[~df['is_blurry']].reset_index(drop=True)

df.shape

"""# Feature Selection Strategy

**Correlations**
"""

def compute_correlations(df, target="label", threshold=0.9):
    corr_matrix = df.corr().abs()

    # 1. Redundant pairs
    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
    redundant_features = [(col, row, upper.loc[row, col])
                          for col in upper.columns
                          for row in upper.index
                          if upper.loc[row, col] > threshold]
    # 2. Correlation with target
    corr_with_target = corr_matrix[target].drop(target).sort_values(ascending=False)

    return redundant_features, corr_with_target

# Step 1: Select only numeric columns
numeric_df = df.select_dtypes(include=[np.number])

# Step 2: Identify non-numeric columns
non_numeric_cols = df.columns.difference(numeric_df.columns)
print("Non-numeric columns:", non_numeric_cols.tolist())

df_encoded= df.drop(columns=['filename', 'path', 'is_blurry', 'size'])  # Features
redundant, corr_with_target = compute_correlations(df_encoded)

# Convert redundant correlations to DataFrame for saving
redundant_df = pd.DataFrame(redundant, columns=["Feature_1", "Feature_2", "Correlation"])

print("Highly correlated feature pairs (>0.9):")
for f1, f2, val in redundant:
    print(f"{f1} ↔ {f2} : {val:.2f}")

# Save to CSV file
file_path = "results/tables/redundant_features.csv"
redundant_df.to_csv(file_path, index=False)

print(f"Saved highly correlated feature/redundant pairs to {file_path}")

# Print top 5 features predictive of diagnosis
print("\nTop 5 features predictive of diagnosis:")
print(corr_with_target.head(5))

# Create folder if it doesn't exist
os.makedirs("results/tables", exist_ok=True)

# Save top 5 features to CSV
top_5_df = corr_with_target.head(5)
file_path = "results/tables/top_5_predictive_features.csv"
top_5_df.to_csv(file_path)

print(f"Top 5 predictive features saved to {file_path}")

# Save top 5 feature data into X_top
top_5_features = top_5_df.index.tolist()
X_top = df[top_5_features]   # DataFrame with top features
top_features = X_top.columns  # Index of feature names
print(top_features)

"""**Mutual Information**

Captures nonlinear relationships between features and the target.
"""

X = df.drop(columns=['label', 'filename', 'path', 'size', 'is_blurry'])
y = df['label']

mi_scores = mutual_info_classif(X, y, random_state=42)
mi_df = pd.DataFrame({'Feature': X.columns, 'MI Score': mi_scores})
mi_df = mi_df.sort_values(by='MI Score', ascending=False)
print(mi_df.head(10))

file_path = "results/tables/top_Mutual_info_classif.csv"
mi_df.to_csv(file_path)

print(f"Top Mutual Information {file_path}")

"""**Tree-Based Feature Importance**"""

model = RandomForestClassifier(random_state=42)
model.fit(X, y)

importances = pd.Series(model.feature_importances_, index=X.columns)
fi_df = importances.sort_values(ascending=False).reset_index()
fi_df.columns = ['Feature', 'Importance']
print(fi_df.head(10))

file_path = "results/tables/top_tree_based_feature.csv"
fi_df.to_csv(file_path)

print(f"Top Tree-Based Feature Importance {file_path}")

"""**Recursive Feature Elimination (RFE)**

Find the best subset of features.
"""

rfe = RFE(estimator=LogisticRegression(max_iter=1000), n_features_to_select=5)
rfe.fit(X, y)

selected_features = X.columns[rfe.support_]
print("Selected features via RFE:", selected_features.tolist())

file_path = "results/tables/top_recursive_feature_elimination.csv"
pd.DataFrame({'Selected Features': selected_features.tolist()}).to_csv(file_path, index=False)


print(f"Top Recursive Feature Elimination (RFE) {file_path}")

"""**Univariate Statistical Tests (ANOVA F-test)**

Rank features by their discriminative power.
"""

selector = SelectKBest(score_func=f_classif, k='all')
selector.fit(X, y)

anova_df = pd.DataFrame({'Feature': X.columns, 'F Score': selector.scores_})
anova_df = anova_df.sort_values(by='F Score', ascending=False)
print(anova_df.head(10))

file_path = "results/tables/top_univariate_statistical.csv"
anova_df.head(10).to_csv(file_path)

print(f"Univariate Statistical Tests {file_path}")

"""**Consensus Selection**

Compare top features across methods and select those that consistently rank high
"""

# Combine top 5 from each method
top_mi = mi_df.head(5)['Feature']
top_rf = fi_df.head(5)['Feature']
top_rfe = pd.Series(selected_features)
top_anova = anova_df.head(5)['Feature']

consensus = pd.concat([top_mi, top_rf, top_rfe, top_anova]).value_counts()
print("Consensus top features:")
print(consensus.head(10))

# Convert consensus Series to DataFrame
consensus_df = consensus.reset_index()
consensus_df.columns = ['Feature', 'Count']

# Create folder if needed
os.makedirs("results/tables", exist_ok=True)

# Save to CSV
file_path = "results/tables/consensus_top_features.csv"
consensus_df.to_csv(file_path, index=False)

print(f"Consensus top features saved to {file_path}")

"""**Visualize Feature Space with PCA**"""

X_selected = df[consensus.head(5).index]  # Top 5 consensus features
y = df['label']

pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_selected)

plt.figure(figsize=(8,6))
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='coolwarm', alpha=0.6)
plt.title("PCA of Top Features")
plt.xlabel("PC1")
plt.ylabel("PC2")
plt.grid(True)
# Save figure to PNG file
plt.savefig("results/plots/pca_top_5_features.png", dpi=300, bbox_inches="tight")
plt.show()

"""**t-SNE for Nonlinear Embedding**"""

tsne = TSNE(n_components=2, random_state=42)
X_tsne = tsne.fit_transform(X_selected)

plt.figure(figsize=(8,6))
plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y, cmap='coolwarm', alpha=0.6)
plt.title("t-SNE of Top Features")
plt.xlabel("Dim 1")
plt.ylabel("Dim 2")
plt.grid(True)
# Save the plot as PNG
plt.savefig("results/plots/tsne_projection.png", dpi=300, bbox_inches="tight")
plt.show()

"""**Attempting Logistic Regression**"""

X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)

model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

print(classification_report(y_test, y_pred))

# Generate report as dictionary
report_dict = classification_report(y_test, y_pred, output_dict=True)

# Convert to DataFrame
report_df = pd.DataFrame(report_dict).transpose()

# Create folder if needed
os.makedirs("results/tables", exist_ok=True)

# Save to CSV
file_path = "results/tables/classification_report.csv"
report_df.to_csv(file_path)

print(f"Classification report saved as table to {file_path}")

"""# Preprocessing the dataset"""

df.shape

print(df.head())

"""# Step 1: DATA PREPARATION"""

def prepare_data(df):
    """Split data into train and test sets"""
    train_df_full, test_df = train_test_split(
        df,
        stratify=df['label'],
        test_size=0.2,
        random_state=42
    )

    print(f"Train set size: {len(train_df_full)}")
    print(f"Test set size: {len(test_df)}")
    print(f"Train label distribution:\n{train_df_full['label'].value_counts()}")
    print(f"Test label distribution:\n{test_df['label'].value_counts()}")

    # Save test_df for later use
    os.makedirs("results/data", exist_ok=True)
    test_df.to_csv("results/data/test_df.csv", index=False)
    train_df_full.to_csv("results/data/train_df_full.csv", index=False)
    print(f"\nSaved test_df to: results/data/test_df.csv")
    print(f"Saved train_df_full to: results/data/train_df_full.csv")

    return train_df_full, test_df

# Define transforms
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),   # flips image left-right
    transforms.RandomRotation(10),        # rotates image ±10 degrees
    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # shifts image up/down/left/right
    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # ±20% variation
    transforms.RandomResizedCrop(224, scale=(0.9, 1.0)), # crop between 90% and 100%
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485], std=[0.229])  # For grayscale
])

val_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485], std=[0.229])
])

"""# STEP 2: DATASET AND DATALOADER"""

class BrainTumorDataset(Dataset):
    """Custom Dataset for Brain Tumor MRI images"""
    def __init__(self, dataframe, transform=None):
        self.df = dataframe
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        img_path = self.df.iloc[idx]['path']
        label = self.df.iloc[idx]['label']
        image = Image.open(img_path).convert("L")  # Grayscale

        if self.transform:
            image = self.transform(image)

        return image, label

def get_weighted_sampler(df):
    """Create weighted sampler for handling class imbalance"""
    class_counts = df['label'].value_counts().to_dict()
    weights = df['label'].apply(lambda x: 1.0 / class_counts[x])
    return WeightedRandomSampler(weights.values, num_samples=len(weights), replacement=True)

def get_dataloaders(df, train_transform, val_transform, batch_size, split_ratio=0.8, use_sampler=True, test_df=None):
    """Create train, validation, and optionally test dataloaders"""
    # Split into train and val
    train_df, val_df = train_test_split(df, stratify=df['label'], test_size=1 - split_ratio, random_state=42)

    # Create datasets
    train_dataset = BrainTumorDataset(train_df, transform=train_transform)
    val_dataset = BrainTumorDataset(val_df, transform=val_transform)

    # Weighted sampler for class imbalance
    if use_sampler:
        sampler = get_weighted_sampler(train_df)
        train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)
    else:
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

    # Optional test loader
    if test_df is not None:
        test_dataset = BrainTumorDataset(test_df, transform=val_transform)
        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
    else:
        test_loader = None

    return train_loader, val_loader, test_loader, train_df, val_df

"""# STEP 3: MODEL BUILDING"""

def build_model(arch, dropout_rate):
    """Build model with specified architecture and dropout rate"""
    if arch == 'resnet50':
        model = models.resnet50(weights='IMAGENET1K_V1')
        model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)
        in_features = model.fc.in_features
        model.fc = nn.Sequential(
            nn.Dropout(dropout_rate),
            nn.Linear(in_features, 1)
        )
    elif arch == 'efficientnet_b0':
        model = models.efficientnet_b0(weights='IMAGENET1K_V1')
        model.features[0][0] = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1, bias=False)
        in_features = model.classifier[1].in_features
        model.classifier[1] = nn.Sequential(
            nn.Dropout(p=dropout_rate),
            nn.Linear(in_features, 1)
        )
    elif arch == 'densenet121':
        model = models.densenet121(weights='IMAGENET1K_V1')
        model.features.conv0 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)
        in_features = model.classifier.in_features
        model.classifier = nn.Sequential(
            nn.Dropout(dropout_rate),
            nn.Linear(in_features, 1)
        )
    else:
        raise ValueError("Unsupported architecture")

    return model

def get_optimizer(optimizer_type, model_parameters, lr, weight_decay):
    """Create optimizer based on type"""
    if optimizer_type == 'Adam':
        return torch.optim.Adam(model_parameters, lr=lr, weight_decay=weight_decay)
    elif optimizer_type == 'SGD':
        return torch.optim.SGD(model_parameters, lr=lr, momentum=0.9, weight_decay=weight_decay)
    elif optimizer_type == 'AdamW':
        return torch.optim.AdamW(model_parameters, lr=lr, weight_decay=weight_decay)
    else:
        raise ValueError(f"Unsupported optimizer: {optimizer_type}")

def get_scheduler(scheduler_type, optimizer):
    """Create learning rate scheduler based on type"""
    if scheduler_type == 'plateau':
        return ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)
        #If you want to monitor learning rate changes
        #scheduler.get_last_lr()
    elif scheduler_type == 'step':
        return StepLR(optimizer, step_size=5, gamma=0.5)
    elif scheduler_type == 'cosine':
        return CosineAnnealingLR(optimizer, T_max=10)
    else:
        raise ValueError(f"Unsupported scheduler: {scheduler_type}")

"""# STEP 4: TRAINING FUNCTION"""

def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, device, num_epochs=20, patience=5, save_name='best_model.pth'):
    """Train model with early stopping"""
    model.to(device)

    best_val_loss = float('inf')
    no_improve_epochs = 0

    train_losses, val_losses = [], []
    val_accuracies, val_aucs = [], []
    val_precisions, val_recalls = [], []

    for epoch in range(num_epochs):
        print(f"\nEpoch {epoch+1}/{num_epochs}")

        # Training phase
        model.train()
        running_train_loss = 0
        for images, labels in tqdm(train_loader, desc="Training", leave=False):
            images = images.to(device)
            labels = labels.float().unsqueeze(1).to(device)

            outputs = model(images)
            loss = criterion(outputs, labels)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            running_train_loss += loss.item()

        avg_train_loss = running_train_loss / len(train_loader)
        train_losses.append(avg_train_loss)

        # Validation phase
        model.eval()
        val_loss = 0
        all_preds, all_labels = [], []

        with torch.no_grad():
            for images, labels in tqdm(val_loader, desc="Validating", leave=False):
                images = images.to(device)
                labels = labels.float().unsqueeze(1).to(device)

                outputs = model(images)
                val_loss += criterion(outputs, labels).item()

                probs = torch.sigmoid(outputs).cpu().numpy()
                all_preds.extend(probs)
                all_labels.extend(labels.cpu().numpy())

        avg_val_loss = val_loss / len(val_loader)
        val_losses.append(avg_val_loss)

        # Metrics
        pred_labels = [1 if p > 0.5 else 0 for p in all_preds]
        val_acc = accuracy_score(all_labels, pred_labels)
        val_auc = roc_auc_score(all_labels, all_preds)
        val_precision = precision_score(all_labels, pred_labels, zero_division=0)
        val_recall = recall_score(all_labels, pred_labels, zero_division=0)

        val_accuracies.append(val_acc)
        val_aucs.append(val_auc)
        val_precisions.append(val_precision)
        val_recalls.append(val_recall)

        print(f"Epoch {epoch+1} Summary:")
        print(f"Train Loss: {avg_train_loss:.4f}")
        print(f"Val Loss: {avg_val_loss:.4f}, Accuracy: {val_acc:.4f}, AUC: {val_auc:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}")

        # Save best model
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            no_improve_epochs = 0
            torch.save(model.state_dict(), save_name)
            print(f"Saved new best model at epoch {epoch+1}")
        else:
            no_improve_epochs += 1
            print(f"No improvement for {no_improve_epochs} epoch(s)")
            if no_improve_epochs >= patience:
                print(f"Early stopping triggered at epoch {epoch+1}")
                break

        # Adjust learning rate
        if isinstance(scheduler, ReduceLROnPlateau):
            scheduler.step(avg_val_loss)
        else:
            scheduler.step()

    return train_losses, val_losses, val_accuracies, val_aucs, val_precisions, val_recalls

"""# STEP 5: HYPERPARAMETER#  OPTIMIZATION"""

def optimize_model(architecture_name, train_df_full, train_transform, val_transform, n_trials=20):
    """Optimize hyperparameters for a specific architecture"""
    print(f"Optimizing hyperparameters for {architecture_name}...")

    optuna_results = []

    def objective(trial):
        # Suggest hyperparameters
        lr = trial.suggest_float('lr', 1e-5, 1e-3, log=True)
        batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])
        dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.5)
        weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-2, log=True)
        optimizer_type = trial.suggest_categorical('optimizer', ['Adam', 'SGD', 'AdamW'])
        scheduler_type = trial.suggest_categorical('scheduler', ['plateau', 'step', 'cosine'])

        # Build model
        model = build_model(architecture_name, dropout_rate)

        # Create dataloaders
        train_loader, val_loader, _, _, _ = get_dataloaders(
            df=train_df_full,
            train_transform=train_transform,
            val_transform=val_transform,
            batch_size=batch_size,
            split_ratio=0.8,
            test_df=None
        )

        # Setup training components
        criterion = nn.BCEWithLogitsLoss()
        optimizer = get_optimizer(optimizer_type, model.parameters(), lr, weight_decay)
        scheduler = get_scheduler(scheduler_type, optimizer)

        # Train
        train_losses, val_losses, val_accuracies, val_aucs, val_precisions, val_recalls = train_model(
            model, train_loader, val_loader, criterion, optimizer, scheduler,
            device=torch.device("cuda" if torch.cuda.is_available() else "cpu"),
            num_epochs=10,
            patience=3,
            save_name=f"trial_{architecture_name}_{trial.number}.pth"
        )

        # Log results
        trial_result = {
            'trial': trial.number,
            'arch': architecture_name,
            'lr': lr,
            'batch_size': batch_size,
            'dropout_rate': dropout_rate,
            'weight_decay': weight_decay,
            'optimizer': optimizer_type,
            'scheduler': scheduler_type,
            'val_loss': val_losses[-1],
            'accuracy': val_accuracies[-1],
            'auc': val_aucs[-1],
            'precision': val_precisions[-1],
            'recall': val_recalls[-1]
        }
        optuna_results.append(trial_result)

        # Return composite metric
        return 0.5 * max(val_aucs) + 0.5 * max(val_recalls)

    # Run optimization
    study = optuna.create_study(direction='maximize')
    study.optimize(objective, n_trials=n_trials)

    print(f"Best parameters for {architecture_name}:")
    print(study.best_trial.params)

    return study.best_trial.params, optuna_results

"""# STEP 6: MAIN EXECUTION PIPELINE"""

def run_pipeline(df, architectures=['resnet50', 'efficientnet_b0', 'densenet121'], n_trials=20):
    """Main pipeline to train and evaluate all models"""

    # Prepare data
    train_df_full, test_df = prepare_data(df)

    # Storage for results
    all_results = []
    all_optuna_results = []

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    # Process each architecture
    for arch in architectures:
        print(f"\n{'='*50}")
        print(f"Processing {arch.upper()}")
        print(f"{'='*50}")

        # Optimize hyperparameters
        best_params, arch_optuna_results = optimize_model(
            arch, train_df_full, train_transform, val_transform, n_trials=n_trials
        )
        all_optuna_results.extend(arch_optuna_results)

        # Train final model with best parameters
        print(f"Training final {arch} model with best parameters...")

        # Extract best parameters
        best_lr = best_params['lr']
        best_batch_size = best_params['batch_size']
        best_dropout = best_params['dropout_rate']
        best_weight_decay = best_params['weight_decay']
        best_optimizer = best_params['optimizer']
        best_scheduler = best_params['scheduler']

        # Build final model
        final_model = build_model(arch, best_dropout)

        # Create dataloaders
        train_loader, val_loader, test_loader, _, _ = get_dataloaders(
            df=train_df_full,
            train_transform=train_transform,
            val_transform=val_transform,
            batch_size=best_batch_size,
            split_ratio=0.8,
            test_df=test_df
        )

        # Setup training
        criterion = nn.BCEWithLogitsLoss()
        optimizer = get_optimizer(best_optimizer, final_model.parameters(), best_lr, best_weight_decay)
        scheduler = get_scheduler(best_scheduler, optimizer)

        # Train final model
        train_losses, val_losses, val_accuracies, val_aucs, val_precisions, val_recalls = train_model(
            final_model, train_loader, val_loader, criterion, optimizer, scheduler,
            device=device,
            num_epochs=20,
            patience=5,
            save_name=f"best_{arch}_model.pth"
        )

        # Evaluate on test set with comprehensive analysis
        print(f"Evaluating {arch} on test set...")

        final_model.load_state_dict(torch.load(f"best_{arch}_model.pth"))
        final_model.eval()
        final_model.to(device)

        # Run comprehensive evaluation
        eval_metrics = evaluate_and_save(
            model=final_model,
            model_name=arch,
            test_loader=test_loader,
            test_df=test_df,
            device=device,
            num_gradcam_samples=6
        )

        # Get basic metrics for comparison table
        all_preds = []
        all_labels = []

        with torch.no_grad():
            for images, labels in test_loader:
                images = images.to(device)
                labels = labels.float().unsqueeze(1).to(device)

                outputs = final_model(images)
                probs = torch.sigmoid(outputs).cpu().numpy()
                all_preds.extend(probs)
                all_labels.extend(labels.cpu().numpy())

        probs_arr, labels_arr = flatten_preds_labels(all_preds, all_labels)
        pred_labels = (probs_arr >= 0.5).astype(int)

        test_acc = accuracy_score(labels_arr, pred_labels)
        test_precision = precision_score(labels_arr, pred_labels, zero_division=0)
        test_recall = recall_score(labels_arr, pred_labels, zero_division=0)
        test_auc = roc_auc_score(labels_arr, probs_arr)

        print(f"\n{arch.upper()} Test Results:")
        print(f"Accuracy:  {test_acc:.4f}")
        print(f"Precision: {test_precision:.4f}")
        print(f"Recall:    {test_recall:.4f}")
        print(f"AUC:       {test_auc:.4f}")

        # Store results
        result = {
            'Model': arch,
            'Accuracy': test_acc,
            'Precision': test_precision,
            'Recall': test_recall,
            'AUC': test_auc,
            'Best_Params': str(best_params)
        }
        all_results.append(result)

    # Save results
    os.makedirs("results/tables", exist_ok=True)
    os.makedirs("results/plots", exist_ok=True)

    optuna_df = pd.DataFrame(all_optuna_results)
    optuna_df.to_csv("results/tables/all_optuna_trials.csv", index=False)

    results_df = pd.DataFrame(all_results)
    results_df.to_csv("results/tables/model_comparison.csv", index=False)

    # Generate combined ROC curve plot
    if roc_registry:
        roc_path = plot_and_save_combined_roc(roc_registry)
        print(f"\nSaved combined ROC curves: {roc_path}")

    print("\n" + "="*60)
    print("FINAL COMPARISON")
    print("="*60)
    print(results_df)
    print("\nAll results saved!")
    print("Optuna trials: results/tables/all_optuna_trials.csv")
    print("Final comparison: results/tables/model_comparison.csv")
    print("\nAdditional outputs per model:")
    print("- Confusion matrices: results/plots/confusion_matrix_*.png")
    print("- Classification reports: results/tables/classification_report_*.txt")
    print("- Error analysis: results/tables/error_analysis_*.csv")
    print("- False positives/negatives: results/tables/false_positives_*.csv")
    print("- Grad-CAM visualizations: results/plots/gradcam_*.png")
    print("- Combined ROC curves: results/plots/roc_curves_combined.png")

    return results_df

"""USAGE EXAMPLE"""

if __name__ == "__main__":
    # Load your dataframe
    # df = pd.read_csv('your_data.csv')
    # or use your existing df

    # Run the complete pipeline
    # results = run_pipeline(df, architectures=['resnet50', 'efficientnet_b0', 'densenet121'], n_trials=20)
    pass

"""# STEP 7: EVALUATION AND VISUALIZATION FUNCTIONS"""

# Global registry for ROC curves
roc_registry = {}

def flatten_preds_labels(all_probs, all_labels):
    """Flatten prediction and label arrays for consistent metric computation"""
    probs = np.vstack(all_probs).ravel() if len(all_probs) and np.array(all_probs[0]).ndim>0 else np.array(all_probs).ravel()
    labels = np.vstack(all_labels).ravel() if len(all_labels) and np.array(all_labels[0]).ndim>0 else np.array(all_labels).ravel()
    probs = probs.astype(float)
    labels = labels.astype(int)
    return probs, labels

def save_confusion_matrix(y_true, y_pred, model_name):
    """Generate and save confusion matrix"""
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(5,4))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
                xticklabels=["No Tumor", "Tumor"],
                yticklabels=["No Tumor", "Tumor"])
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.title(f"Confusion Matrix - {model_name}")
    outp = f"results/plots/confusion_matrix_{model_name}.png"
    plt.savefig(outp, bbox_inches="tight", dpi=150)
    plt.show()  # Display in notebook
    plt.close()
    return outp

def save_classification_report(y_true, y_pred, y_probs, model_name):
    """Generate and save classification report with AUC"""
    rep = classification_report(y_true, y_pred, target_names=["No Tumor","Tumor"], zero_division=0)

    # Calculate AUC
    auc_score = roc_auc_score(y_true, y_probs)

    # Add AUC to the report
    full_report = rep + f"\n\nAUC-ROC Score: {auc_score:.4f}\n"

    with open(f"results/tables/classification_report_{model_name}.txt", "w") as f:
        f.write(full_report)

    return full_report

def plot_and_save_combined_roc(registry, outpath="results/plots/roc_curves_combined.png"):
    """Plot ROC curves for all models on one figure"""
    plt.figure(figsize=(7,6))
    for name, (y_true, y_probs) in registry.items():
        fpr, tpr, _ = roc_curve(y_true, y_probs)
        roc_auc = auc(fpr, tpr)
        plt.plot(fpr, tpr, lw=2, label=f"{name} (AUC={roc_auc:.3f})")
    plt.plot([0,1],[0,1], linestyle="--", color="gray")
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("ROC Curves (All Models)")
    plt.legend(loc="lower right")
    plt.savefig(outpath, bbox_inches="tight", dpi=150)
    plt.close()
    return outpath

"""# STEP 8: GRAD-CAM IMPLEMENTATION"""

def _get_last_conv_module(model, model_name):
    """Identify the last convolutional layer for Grad-CAM"""
    name = model_name.lower()

    # ResNet
    if 'resnet' in name:
        return getattr(model, 'layer4', None)

    # DenseNet
    if 'densenet' in name:
        feats = getattr(model, 'features', None)
        for m in reversed(list(feats.named_modules())):
            if isinstance(m[1], torch.nn.Conv2d):
                return m[1]
        return feats

    # EfficientNet
    if 'efficientnet' in name:
        feats = getattr(model, 'features', None)
        last = None
        for n, ch in feats.named_children():
            last = ch
        return last

    # Fallback: search for last Conv2d in model
    last_conv = None
    for n, m in model.named_modules():
        if isinstance(m, torch.nn.Conv2d):
            last_conv = m
    return last_conv

def compute_gradcam_for_image(model, model_name, pil_image, device):
    """Compute Grad-CAM heatmap for a single image"""
    model.eval()

    # Prepare input tensor (keep as 1 channel for grayscale models)
    preprocess = transforms.Compose([
        transforms.Resize((224,224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485], std=[0.229])
    ])
    x = preprocess(pil_image).unsqueeze(0).to(device)
    # Don't convert to 3 channels - models are modified for 1 channel input

    # Find target conv module & register hooks
    target_conv = _get_last_conv_module(model, model_name)
    if target_conv is None:
        raise RuntimeError("Could not identify last conv layer for Grad-CAM")

    activations = {}
    gradients = {}

    def forward_hook(module, input, output):
        activations['value'] = output.detach()

    def backward_hook(module, grad_in, grad_out):
        gradients['value'] = grad_out[0].detach()

    fh = target_conv.register_forward_hook(forward_hook)
    bh = target_conv.register_full_backward_hook(backward_hook)

    # Forward pass
    model.zero_grad()
    out = model(x)
    if out.numel() == 1:
        score = out.squeeze()
    else:
        pred_idx = out.argmax(dim=1).item()
        score = out[0, pred_idx]

    # Backward pass
    score.backward(retain_graph=True)

    # Get activations and gradients
    act = activations.get('value')
    grad = gradients.get('value')
    if act is None or grad is None:
        fh.remove(); bh.remove()
        raise RuntimeError("Grad-CAM failed to capture activations or gradients")

    # Compute weighted combination
    weights = torch.mean(grad, dim=(2,3), keepdim=True)
    gcam = torch.sum(weights * act, dim=1, keepdim=True)
    gcam = torch.relu(gcam)
    gcam = F.interpolate(gcam, size=(224,224), mode='bilinear', align_corners=False)
    gcam = gcam.squeeze().cpu().numpy()

    # Normalize
    gcam -= gcam.min()
    if gcam.max() > 0:
        gcam /= gcam.max()

    # Remove hooks
    fh.remove(); bh.remove()

    return gcam

def overlay_heatmap_on_image(pil_img, heatmap, alpha=0.5, cmap='jet'):
    """Overlay Grad-CAM heatmap on original image"""
    img = np.array(pil_img.resize((224,224)))
    if img.ndim == 2:
        base = np.stack([img]*3, axis=-1)
    else:
        base = img
    cmap_ = plt.get_cmap(cmap)
    hm = cmap_(heatmap)[:,:,:3] * 255.0
    overlay = (1-alpha) * base.astype(float) + alpha * hm.astype(float)
    overlay = np.clip(overlay, 0, 255).astype(np.uint8)
    return overlay

"""# STEP 9: COMPREHENSIVE EVALUATION FUNCTION"""

def evaluate_and_save(model, model_name, test_loader, test_df, device, num_gradcam_samples=6):
    """
    Comprehensive evaluation: metrics, confusion matrix, classification report,
    error analysis, false positives/negatives, and Grad-CAM visualizations
    """
    model.to(device)
    model.eval()

    print(f"\nEvaluating {model_name}...")

    # Collect predictions from test_loader
    all_probs = []
    all_labels = []

    with torch.no_grad():
        for images, labels in tqdm(test_loader, desc=f"Predicting {model_name}", leave=False):
            images = images.to(device)
            labels = labels.float().unsqueeze(1).to(device)
            out = model(images)
            probs = torch.sigmoid(out).cpu().numpy()
            all_probs.extend(probs)
            all_labels.extend(labels.cpu().numpy())

    probs_arr, labels_arr = flatten_preds_labels(all_probs, all_labels)
    pred_labels = (probs_arr >= 0.5).astype(int)

    # Save confusion matrix & classification report (with AUC)
    cm_path = save_confusion_matrix(labels_arr, pred_labels, model_name)
    rep = save_classification_report(labels_arr, pred_labels, probs_arr, model_name)
    print(f"Saved confusion matrix: {cm_path}")
    print(f"Classification report:\n{rep}")

    # Save ROC data for combined plotting later
    roc_registry[model_name] = (labels_arr, probs_arr)

    # Error analysis: iterate through test_df for detailed per-image analysis
    error_rows = []
    sample_for_gradcam = []

    with torch.no_grad():
        for i, row in tqdm(test_df.reset_index(drop=True).iterrows(),
                          desc=f"Error analysis {model_name}", leave=False):
            img_path = row['path']
            true_label = int(row['label'])
            pil = Image.open(img_path).convert("L")

            # Transform and predict (keep as 1 channel, don't convert to 3)
            transform = transforms.Compose([
                transforms.Resize((224,224)),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485], std=[0.229])
            ])
            x = transform(pil).unsqueeze(0).to(device)

            out = model(x)
            prob = torch.sigmoid(out).item()
            pred = 1 if prob >= 0.5 else 0

            error_rows.append({
                'filename': os.path.basename(img_path),
                'path': img_path,
                'true_label': true_label,
                'pred_label': pred,
                'probability': prob
            })

            # Collect misclassified samples for Grad-CAM
            if pred != true_label:
                sample_for_gradcam.append((img_path, true_label, pred, prob))

    error_df = pd.DataFrame(error_rows)
    error_df.to_csv(f"results/tables/error_analysis_{model_name}.csv", index=False)
    print(f"Saved error analysis: results/tables/error_analysis_{model_name}.csv")
    print(f"\nError Analysis Summary (first 10 rows):")
    print(error_df.head(10))

    # Save false positives and false negatives
    false_pos = error_df[(error_df['true_label']==0) & (error_df['pred_label']==1)].sort_values('probability', ascending=False).head(10)
    false_neg = error_df[(error_df['true_label']==1) & (error_df['pred_label']==0)].sort_values('probability', ascending=True).head(10)
    false_pos.to_csv(f"results/tables/false_positives_{model_name}.csv", index=False)
    false_neg.to_csv(f"results/tables/false_negatives_{model_name}.csv", index=False)
    print(f"Saved false positives/negatives")
    print(f"\nFalse Positives ({len(false_pos)} cases):")
    if len(false_pos) > 0:
        print(false_pos[['filename', 'probability']])
    else:
        print("None")
    print(f"\nFalse Negatives ({len(false_neg)} cases):")
    if len(false_neg) > 0:
        print(false_neg[['filename', 'probability']])
    else:
        print("None")

    # Grad-CAM: choose samples (prefer misclassified)
    gradcam_samples = []
    mis_samples = sample_for_gradcam[:num_gradcam_samples]
    gradcam_samples.extend(mis_samples)

    # Add correctly classified samples if needed
    if len(gradcam_samples) < num_gradcam_samples:
        correct_df = error_df[error_df['true_label'] == error_df['pred_label']]
        picks = correct_df.sample(min(len(correct_df), num_gradcam_samples - len(gradcam_samples)), random_state=42)
        for _, r in picks.iterrows():
            gradcam_samples.append((r['path'], int(r['true_label']), int(r['pred_label']), r['probability']))

    # Grad-CAM: choose samples (prefer misclassified)
    gradcam_samples = []
    mis_samples = sample_for_gradcam[:num_gradcam_samples]
    gradcam_samples.extend(mis_samples)

    # Add correctly classified samples if needed
    if len(gradcam_samples) < num_gradcam_samples:
        correct_df = error_df[error_df['true_label'] == error_df['pred_label']]
        picks = correct_df.sample(min(len(correct_df), num_gradcam_samples - len(gradcam_samples)), random_state=42)
        for _, r in picks.iterrows():
            gradcam_samples.append((r['path'], int(r['true_label']), int(r['pred_label']), r['probability']))

    # Generate Grad-CAM visualizations
    os.makedirs("results/plots", exist_ok=True)
    print(f"\nGrad-CAM Visualizations:")

    # Create a figure to display all Grad-CAM images
    num_samples = len(gradcam_samples)
    if num_samples > 0:
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        axes = axes.flatten()

        for idx, (img_path, true_lbl, pred_lbl, prob) in enumerate(gradcam_samples):
            if idx >= 6:  # Only show up to 6
                break

            pil = Image.open(img_path).convert("L")
            try:
                hm = compute_gradcam_for_image(model, model_name, pil, device)
                overlay = overlay_heatmap_on_image(pil, hm, alpha=0.5)
                out_name = f"results/plots/gradcam_{model_name}_{idx}_t{true_lbl}_p{pred_lbl}_{os.path.basename(img_path)}"
                plt.imsave(out_name, overlay)

                # Display in subplot
                axes[idx].imshow(overlay)
                axes[idx].axis('off')
                axes[idx].set_title(f"True: {true_lbl}, Pred: {pred_lbl}\nProb: {prob:.3f}", fontsize=10)
            except Exception as e:
                print(f"Grad-CAM failed for {img_path}: {e}")
                axes[idx].axis('off')

        # Hide unused subplots
        for idx in range(len(gradcam_samples), 6):
            axes[idx].axis('off')

        plt.suptitle(f"Grad-CAM Visualizations - {model_name}", fontsize=14, fontweight='bold')
        plt.tight_layout()
        plt.show()
        plt.close()

    print(f"Saved Grad-CAM images (up to {num_gradcam_samples} samples)")

    metrics = {
        'confusion_matrix': cm_path,
        'classification_report': f"results/tables/classification_report_{model_name}.txt",
        'error_csv': f"results/tables/error_analysis_{model_name}.csv",
        'false_pos': f"results/tables/false_positives_{model_name}.csv",
        'false_neg': f"results/tables/false_negatives_{model_name}.csv"
    }

    return metrics

"""Checking separatly

Dont run if running all the project
"""

# You already have everything in your pipeline code. Just run this:

# 1. Load your test data (you already have this from earlier)
# test_df is your test dataframe from the train/test split
train_df_full, test_df = train_test_split(
    df,
    stratify=df['label'],
    test_size=0.2,
    random_state=42
    )
os.makedirs("results/data", exist_ok=True)
test_df.to_csv("results/data/test_df.csv", index=False)
train_df_full.to_csv("results/data/train_df_full.csv", index=False)

# 2. Create test dataloader
test_dataset = BrainTumorDataset(test_df, transform=val_transform)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# 3. Load a saved model
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = build_model('efficientnet_b0', dropout_rate=0.0)  # or 'efficientnet_b0', 'densenet121'
model.load_state_dict(torch.load('/kaggle/input/best_efficientnet_b0_model/pytorch/default/1/best_efficientnet_b0_model.pth'))
model.to(device)

# 4. Run evaluation - this generates everything
metrics = evaluate_and_save(
    model=model,
    model_name='efficientnet_b0',
    test_loader=test_loader,
    test_df=test_df,
    device=device,
    num_gradcam_samples=6
)

# creates:
# - Confusion matrix
# - Classification report
# - Error analysis CSV
# - False positives/negatives tables
# - Grad-CAM visualizations

############# densenet121

# 3. Load a saved model   densenet121
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = build_model('densenet121', dropout_rate=0.0)  # or 'efficientnet_b0', 'densenet121'
model.load_state_dict(torch.load('/kaggle/input/best_densenet121_model/pytorch/default/1/best_densenet121_model.pth'))
model.to(device)

# 4. Run evaluation - this generates everything
metrics = evaluate_and_save(
    model=model,
    model_name='densenet121',
    test_loader=test_loader,
    test_df=test_df,
    device=device,
    num_gradcam_samples=6
)
############# resnet50

# 3. Load a saved model
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = build_model('resnet50', dropout_rate=0.0)  # or 'efficientnet_b0', 'densenet121'
model.load_state_dict(torch.load('/kaggle/input/best_resnet50_model/pytorch/default/1/best_resnet50_model.pth'))
model.to(device)

# 4. Run evaluation - this generates everything
metrics = evaluate_and_save(
    model=model,
    model_name='resnet50',
    test_loader=test_loader,
    test_df=test_df,
    device=device,
    num_gradcam_samples=6
)

results = run_pipeline(
    df=df,
    architectures=['resnet50', 'efficientnet_b0', 'densenet121'],
    n_trials=20
)

"""# STEP 10: Advanced Explainability Analysis

MODEL BUILDING
"""

def build_model(arch, dropout_rate=0.0):
    """Build model with specified architecture"""
    if arch == 'resnet50':
        model = models.resnet50(weights='IMAGENET1K_V1')
        model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)
        in_features = model.fc.in_features
        model.fc = nn.Sequential(
            nn.Dropout(dropout_rate),
            nn.Linear(in_features, 1)
        )
    elif arch == 'efficientnet_b0':
        model = models.efficientnet_b0(weights='IMAGENET1K_V1')
        model.features[0][0] = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1, bias=False)
        in_features = model.classifier[1].in_features
        model.classifier[1] = nn.Sequential(
            nn.Dropout(p=dropout_rate),
            nn.Linear(in_features, 1)
        )
    elif arch == 'densenet121':
        model = models.densenet121(weights='IMAGENET1K_V1')
        model.features.conv0 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)
        in_features = model.classifier.in_features
        model.classifier = nn.Sequential(
            nn.Dropout(dropout_rate),
            nn.Linear(in_features, 1)
        )
    else:
        raise ValueError("Unsupported architecture")

    return model

"""INTEGRATED GRADIENTS"""

def integrated_gradients(model, input_tensor, baseline=None, steps=50, device='cuda'):
    """
    Compute Integrated Gradients attribution

    Args:
        model: PyTorch model
        input_tensor: Input image tensor (1, C, H, W)
        baseline: Baseline tensor (default: zeros)
        steps: Number of integration steps
        device: Device to run on

    Returns:
        attributions: Attribution map (C, H, W)
    """
    model.eval()

    if baseline is None:
        baseline = torch.zeros_like(input_tensor)

    # Generate interpolated inputs between baseline and input
    alphas = torch.linspace(0, 1, steps).to(device)

    # Compute gradients at each interpolated input
    gradients = []

    for alpha in alphas:
        # Interpolate
        interpolated = baseline + alpha * (input_tensor - baseline)
        interpolated.requires_grad = True

        # Forward pass
        output = model(interpolated)

        # Get prediction score
        if output.numel() == 1:
            score = output.squeeze()
        else:
            score = torch.sigmoid(output).squeeze()

        # Backward pass
        model.zero_grad()
        score.backward()

        # Store gradients
        gradients.append(interpolated.grad.detach())

    # Average gradients and multiply by (input - baseline)
    avg_gradients = torch.stack(gradients).mean(dim=0)
    integrated_grads = (input_tensor - baseline) * avg_gradients

    return integrated_grads.squeeze().cpu().numpy()

def visualize_integrated_gradients(ig_attributions, original_image, percentile=99):
    """
    Visualize Integrated Gradients attributions

    Args:
        ig_attributions: Attribution array (C, H, W) or (H, W)
        original_image: PIL Image
        percentile: Percentile for attribution clipping

    Returns:
        overlay: RGB overlay image
    """
    # Handle single channel
    if ig_attributions.ndim == 3:
        ig_attributions = ig_attributions[0]  # Take first channel

    # Normalize attributions
    attribution_abs = np.abs(ig_attributions)
    vmax = np.percentile(attribution_abs, percentile)
    attribution_norm = np.clip(attribution_abs / (vmax + 1e-10), 0, 1)

    # Resize original image
    img_array = np.array(original_image.resize((224, 224)))
    if img_array.ndim == 2:
        img_array = np.stack([img_array]*3, axis=-1)

    # Create heatmap
    cmap = plt.get_cmap('jet')
    heatmap = cmap(attribution_norm)[:,:,:3] * 255

    # Overlay
    overlay = 0.6 * img_array + 0.4 * heatmap
    overlay = np.clip(overlay, 0, 255).astype(np.uint8)

    return overlay

"""GRAD-CAM++"""

def _get_last_conv_module(model, model_name):
    """Identify last convolutional layer"""
    name = model_name.lower()

    if 'resnet' in name:
        return getattr(model, 'layer4', None)

    if 'densenet' in name:
        feats = getattr(model, 'features', None)
        for m in reversed(list(feats.named_modules())):
            if isinstance(m[1], torch.nn.Conv2d):
                return m[1]
        return feats

    if 'efficientnet' in name:
        feats = getattr(model, 'features', None)
        last = None
        for n, ch in feats.named_children():
            last = ch
        return last

    # Fallback
    last_conv = None
    for n, m in model.named_modules():
        if isinstance(m, torch.nn.Conv2d):
            last_conv = m
    return last_conv

def gradcam_plusplus(model, model_name, input_tensor, device='cuda'):
    """
    Compute Grad-CAM++ attribution

    Args:
        model: PyTorch model
        model_name: Model architecture name
        input_tensor: Input image tensor (1, C, H, W)
        device: Device to run on

    Returns:
        heatmap: Attribution heatmap (H, W)
    """
    model.eval()

    # Find target layer
    target_layer = _get_last_conv_module(model, model_name)
    if target_layer is None:
        raise RuntimeError("Could not identify last conv layer")

    activations = {}
    gradients = {}

    def forward_hook(module, input, output):
        activations['value'] = output.detach()

    def backward_hook(module, grad_in, grad_out):
        gradients['value'] = grad_out[0].detach()

    fh = target_layer.register_forward_hook(forward_hook)
    bh = target_layer.register_full_backward_hook(backward_hook)

    # Forward pass
    model.zero_grad()
    output = model(input_tensor)

    if output.numel() == 1:
        score = output.squeeze()
    else:
        score = torch.sigmoid(output).squeeze()

    # Backward pass
    score.backward()

    # Get activations and gradients
    A = activations['value']  # (1, C, H, W)
    grad = gradients['value']  # (1, C, H, W)

    # Compute Grad-CAM++ weights
    grad_2 = grad.pow(2)
    grad_3 = grad.pow(3)

    # Alpha weights (Grad-CAM++ specific)
    alpha_num = grad_2
    alpha_denom = 2 * grad_2 + (grad_3 * A).sum(dim=(2, 3), keepdim=True)
    alpha_denom = torch.where(alpha_denom != 0, alpha_denom, torch.ones_like(alpha_denom))
    alpha = alpha_num / alpha_denom

    # Weights with ReLU
    weights = (alpha * F.relu(grad)).sum(dim=(2, 3), keepdim=True)

    # Weighted combination
    gcam = (weights * A).sum(dim=1, keepdim=True)
    gcam = F.relu(gcam)

    # Upsample to input size
    gcam = F.interpolate(gcam, size=(224, 224), mode='bilinear', align_corners=False)
    gcam = gcam.squeeze().cpu().numpy()

    # Normalize
    gcam = gcam - gcam.min()
    if gcam.max() > 0:
        gcam = gcam / gcam.max()

    # Remove hooks
    fh.remove()
    bh.remove()

    return gcam

def overlay_heatmap_on_image(pil_img, heatmap, alpha=0.5, cmap='jet'):
    """Overlay heatmap on original image"""
    img = np.array(pil_img.resize((224, 224)))
    if img.ndim == 2:
        base = np.stack([img]*3, axis=-1)
    else:
        base = img

    cmap_ = plt.get_cmap(cmap)
    hm = cmap_(heatmap)[:,:,:3] * 255.0
    overlay = (1-alpha) * base.astype(float) + alpha * hm.astype(float)
    overlay = np.clip(overlay, 0, 255).astype(np.uint8)
    return overlay

"""COMPREHENSIVE ANALYSIS FUNCTION"""

def analyze_model_with_advanced_methods(
    model_path,
    architecture,
    test_df,
    num_samples=6,
    methods=['integrated_gradients', 'gradcam++'],
    device='cuda'
):
    """
    Analyze saved model with Integrated Gradients and Grad-CAM++

    Args:
        model_path: Path to saved .pth file
        architecture: Model architecture name
        test_df: Test dataframe with 'path' and 'label' columns
        num_samples: Number of samples to visualize
        methods: List of methods to apply
        device: Device to run on

    Returns:
        results: Dictionary with analysis results
    """
    device = torch.device(device if torch.cuda.is_available() else 'cpu')

    print(f"\n{'='*60}")
    print(f"Analyzing {architecture} with advanced explainability methods")
    print(f"{'='*60}")

    # Load model
    model = build_model(architecture, dropout_rate=0.0)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.to(device)
    model.eval()

    print(f"Loaded model from {model_path}")

    # Prepare transform
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485], std=[0.229])
    ])

    # Get predictions and select samples
    print("Selecting samples for analysis...")
    sample_data = []

    for idx, row in test_df.iterrows():
        img_path = row['path']
        true_label = int(row['label'])

        pil_img = Image.open(img_path).convert("L")
        input_tensor = transform(pil_img).unsqueeze(0).to(device)

        with torch.no_grad():
            output = model(input_tensor)
            prob = torch.sigmoid(output).item()
            pred = 1 if prob >= 0.5 else 0

        sample_data.append({
            'path': img_path,
            'true_label': true_label,
            'pred_label': pred,
            'probability': prob,
            'correct': true_label == pred
        })

    sample_df = pd.DataFrame(sample_data)

    # Select diverse samples: some correct, some incorrect
    incorrect = sample_df[~sample_df['correct']].head(num_samples // 2)
    correct = sample_df[sample_df['correct']].sample(min(len(sample_df[sample_df['correct']]),
                                                         num_samples - len(incorrect)),
                                                     random_state=42)
    selected_samples = pd.concat([incorrect, correct]).head(num_samples)

    print(f"Selected {len(selected_samples)} samples for visualization")

    # Create output directory
    os.makedirs(f"results/advanced_explainability/{architecture}", exist_ok=True)

    # Analyze each sample
    for method in methods:
        print(f"\nGenerating {method} visualizations...")

        num_cols = 3
        num_rows = (len(selected_samples) + num_cols - 1) // num_cols
        fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 5*num_rows))
        axes = axes.flatten() if num_rows > 1 else [axes] if num_cols == 1 else axes

        for idx, (_, sample) in enumerate(selected_samples.iterrows()):
            img_path = sample['path']
            true_lbl = sample['true_label']
            pred_lbl = sample['pred_label']
            prob = sample['probability']

            pil_img = Image.open(img_path).convert("L")
            input_tensor = transform(pil_img).unsqueeze(0).to(device)

            try:
                if method == 'integrated_gradients':
                    attributions = integrated_gradients(model, input_tensor, steps=50, device=device)
                    overlay = visualize_integrated_gradients(attributions, pil_img)
                elif method == 'gradcam++':
                    heatmap = gradcam_plusplus(model, architecture, input_tensor, device=device)
                    overlay = overlay_heatmap_on_image(pil_img, heatmap)

                # Save individual image
                save_path = f"results/advanced_explainability/{architecture}/{method}_{idx}_t{true_lbl}_p{pred_lbl}_{os.path.basename(img_path)}"
                plt.imsave(save_path, overlay)

                # Display in subplot
                axes[idx].imshow(overlay)
                axes[idx].axis('off')
                status = "✓" if true_lbl == pred_lbl else "✗"
                axes[idx].set_title(f"{status} True: {true_lbl}, Pred: {pred_lbl}\nProb: {prob:.3f}",
                                   fontsize=10)

            except Exception as e:
                print(f"Failed for {img_path}: {e}")
                axes[idx].axis('off')

        # Hide unused subplots
        for idx in range(len(selected_samples), len(axes)):
            axes[idx].axis('off')

        method_title = method.replace('_', ' ').title()
        plt.suptitle(f"{method_title} - {architecture}", fontsize=14, fontweight='bold')
        plt.tight_layout()
        plt.savefig(f"results/advanced_explainability/{architecture}/{method}_combined.png",
                   dpi=150, bbox_inches='tight')
        plt.show()
        plt.close()

    print(f"\nAnalysis complete for {architecture}!")
    print(f"Results saved to: results/advanced_explainability/{architecture}/")

    return {
        'model': architecture,
        'samples_analyzed': len(selected_samples),
        'methods': methods
    }

"""BATCH ANALYSIS FOR ALL MODELS"""

def analyze_all_models(model_configs, test_df, num_samples=6, device='cuda'):
    """
    Analyze all saved models with advanced explainability methods

    Args:
        model_configs: List of dicts with 'path' and 'arch' keys
        test_df: Test dataframe
        num_samples: Number of samples per model
        device: Device to run on

    Returns:
        all_results: List of analysis results
    """
    all_results = []

    for config in model_configs:
        result = analyze_model_with_advanced_methods(
            model_path=config['path'],
            architecture=config['arch'],
            test_df=test_df,
            num_samples=num_samples,
            methods=['integrated_gradients', 'gradcam++'],
            device=device
        )
        all_results.append(result)

    print("\n" + "="*60)
    print("ALL MODELS ANALYZED")
    print("="*60)
    print(f"Total models: {len(all_results)}")
    print(f"Output directory: results/advanced_explainability/")

    return all_results

"""USAGE"""

# Dont run this
train_df_full, test_df = train_test_split(
    df,
    stratify=df['label'],
    test_size=0.2,
    random_state=42
    )
    # Save test_df for later use
os.makedirs("results/data", exist_ok=True)
test_df.to_csv("results/data/test_df.csv", index=False)
train_df_full.to_csv("results/data/train_df_full.csv", index=False)

if __name__ == "__main__":



    # Load your test dataframe
    test_df = pd.read_csv('/kaggle/working/results/data/test_df.csv')  # or use your prepared test_df

    # Define model configurations

    model_configs = [
        {'path': 'best_resnet50_model.pth', 'arch': 'resnet50'},
        {'path': 'best_efficientnet_b0_model.pth', 'arch': 'efficientnet_b0'},
        {'path': 'best_densenet121_model.pth', 'arch': 'densenet121'}
    ]

    # Analyze all models
    results = analyze_all_models(
        model_configs=model_configs,
        test_df=test_df,
        num_samples=6,
        device='cuda'
    )
    """
    # Or analyze single model
    result = analyze_model_with_advanced_methods(
        model_path='best_resnet50_model.pth',
        architecture='resnet50',
        test_df=test_df,
        num_samples=6,
        methods=['integrated_gradients', 'gradcam++'],
        device='cuda'
    )
    """

    pass

"""Results"""

for root, dirs, files in os.walk("results"):
    level = root.replace("results", "").count(os.sep)
    indent = " " * 4 * (level)
    print(f"{indent}{os.path.basename(root)}/")
    subindent = " " * 4 * (level + 1)
    for f in files:
        print(f"{subindent}{f}")

"""# Documentation"""

# Paths
BASE_DIR = "results"
PLOTS_DIR = os.path.join(BASE_DIR, "plots")
TABLES_DIR = os.path.join(BASE_DIR, "tables")
EXPLAIN_DIR = os.path.join(BASE_DIR, "advanced_explainability")

# Create doc
doc = Document()

# --- Cover Page ---
doc.add_heading("MRI Brain Scan Classifier Report", 0)
doc.add_paragraph("Models: ResNet-50, DenseNet-121, EfficientNet-B0")
doc.add_paragraph("Dataset: Brain MRI Images")
doc.add_paragraph("Author: KaiClone\nDate: 2025")

doc.add_page_break()

# --- Introduction ---
doc.add_heading("1. Introduction", level=1)
doc.add_paragraph("This report presents the results of classifying brain MRI scans "
                  "into Tumor vs No Tumor categories using three deep learning architectures: "
                  "ResNet-50, DenseNet-121, and EfficientNet-B0. "
                  "We include exploratory data analysis (EDA), model evaluation metrics, "
                  "explainability results, and error analysis.")

# --- EDA Section ---
doc.add_heading("2. Exploratory Data Analysis (EDA)", level=1)
eda_images = [
    "class_distribution.png",
    "image_dimensions_distribution.png",
    "aspect_ratio_distribution.png",
    "average_intensity_distribution.png",
    "contrast_distribution_by_class.png",
    "intensity_distribution_by_class.png",
    "image_noise_distribution.png",
    "image_sharpness_distribution.png",
    "tsne_projection.png",
    "pca_top_5_features.png"
]

for img in eda_images:
    path = os.path.join(PLOTS_DIR, img)
    if os.path.exists(path):
        doc.add_paragraph(img.replace("_", " ").replace(".png", "").title())
        doc.add_picture(path, width=Inches(5.5))
        doc.add_paragraph("")  # spacing

doc.add_page_break()

# --- Model Evaluation ---
models = ["resnet50", "densenet121", "efficientnet_b0"]

for model in models:
    doc.add_heading(f"3. Model Evaluation – {model.upper()}", level=1)

    # Confusion matrix
    cm_path = os.path.join(PLOTS_DIR, f"confusion_matrix_{model}.png")
    if os.path.exists(cm_path):
        doc.add_paragraph("Confusion Matrix:")
        doc.add_picture(cm_path, width=Inches(5))

    # Classification report
    cr_path = os.path.join(TABLES_DIR, f"classification_report_{model}.txt")
    if os.path.exists(cr_path):
        doc.add_paragraph("Classification Report:")
        with open(cr_path, "r") as f:
            doc.add_paragraph(f.read())

    # Error analysis
    ea_path = os.path.join(TABLES_DIR, f"error_analysis_{model}.csv")
    if os.path.exists(ea_path):
        doc.add_paragraph("Error Analysis (first 10 rows):")
        df = pd.read_csv(ea_path).head(10)
        table = doc.add_table(rows=1, cols=len(df.columns))
        table.style = "Light List Accent 1"
        hdr_cells = table.rows[0].cells
        for i, col in enumerate(df.columns):
            hdr_cells[i].text = col
        for _, row in df.iterrows():
            row_cells = table.add_row().cells
            for i, col in enumerate(df.columns):
                row_cells[i].text = str(row[col])

    doc.add_page_break()

# --- Explainability Section ---
doc.add_heading("4. Explainability (Grad-CAM & Integrated Gradients)", level=1)

for model in models:
    doc.add_heading(model.upper(), level=2)
    model_dir = os.path.join(EXPLAIN_DIR, model)

    if os.path.exists(model_dir):
        # Expected combined images
        combined_images = [
            ("gradcam++_combined.png", "Grad-CAM++ visualization for"),
            ("integrated_gradients_combined.png", "Integrated Gradients visualization for")
        ]

        for img_name, caption_text in combined_images:
            img_path = os.path.join(model_dir, img_name)
            if os.path.exists(img_path):
                # Add subheading before the image
                doc.add_paragraph(img_name.replace("_combined.png", "").replace("_", " ").title())

                # Add the image
                doc.add_picture(img_path, width=Inches(5.5))

                # Add centered caption below
                last_paragraph = doc.paragraphs[-1]
                last_paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER

                caption = doc.add_paragraph(f"Figure: {caption_text} {model.upper()}")
                caption.alignment = WD_ALIGN_PARAGRAPH.CENTER
                caption.style = 'Caption'
    else:
        doc.add_paragraph("Explainability images not found for this model.")

    doc.add_page_break()


# --- Model Comparison ---
doc.add_heading("5. Model Comparison", level=1)
comp_path = os.path.join(TABLES_DIR, "model_comparison.csv")
if os.path.exists(comp_path):
    df = pd.read_csv(comp_path)
    table = doc.add_table(rows=1, cols=len(df.columns))
    table.style = "Light List Accent 2"
    hdr_cells = table.rows[0].cells
    for i, col in enumerate(df.columns):
        hdr_cells[i].text = col
    for _, row in df.iterrows():
        row_cells = table.add_row().cells
        for i, col in enumerate(df.columns):
            row_cells[i].text = str(row[col])

# --- Conclusion ---
doc.add_heading("6. Conclusion", level=1)
doc.add_paragraph("EfficientNet-B0 achieved the highest accuracy (97.7%) and perfect AUC (1.0), "
                  "outperforming ResNet-50 and DenseNet-121. "
                  "Explainability methods such as Grad-CAM++ and Integrated Gradients confirm "
                  "that the models focus on relevant tumor regions. "
                  "This system demonstrates high reliability in brain tumor detection, "
                  "but future work should include multi-class classification and external validation.")

# Save document
doc.save("Brain_MRI_Classification_Report.docx")

print("✅ Report generated: Brain_MRI_Classification_Report.docx")